#!/usr/bin/env python3
"""Three-minute unipandas API demo orchestrator.

This program provides a single entry point to quickly showcase the
unipandas API across multiple backends in approximately three minutes.
It does so by:

1) Ensuring tiny sample CSV inputs exist under ``data/`` (fast to generate)
2) Running the API demo smoke script (``scripts/api_demo/smoke_reports.py``)
   which produces multiple Markdown fragments under ``reports/api_demo``
3) Aggregating those fragments into one top-level Markdown report at
   ``reports/api_demo/demo_api_3_min.md``

Design goals:
- Keep every function to no more than seven statements.
- Group functions that call each other close together for readability.
- Add docstrings and line-by-line comments on non-obvious code.
"""

import os
import subprocess
import sys
import time
import platform
from pathlib import Path
from datetime import datetime


# Repository paths
# Resolve repository root as the directory containing this file
ROOT = Path(__file__).resolve().parent
# Location for small, quick-to-generate CSVs used by demos
DATA = ROOT / "data"
# Write reports under scripts/reports/api_demo namespace (one level up under scripts)
REPORTS = ROOT / "scripts" / "reports" / "api_demo"
# Ensure directory exists before writing any fragments or aggregates
REPORTS.mkdir(parents=True, exist_ok=True)
# Aggregated output produced by this script
REPORT = REPORTS / "demo_api_3_min.md"

# Script paths used by the orchestrator
# Individual scripts used by the demo
BENCH = ROOT / "scripts" / "api_demo" / "bench_backends.py"
COMPAT = ROOT / "scripts" / "api_demo" / "compat_matrix.py"
REL = ROOT / "scripts" / "api_demo" / "relational_bench.py"
BRC = ROOT / "scripts" / "brc" / "billion_row_challenge.py"
BRC_OM = ROOT / "scripts" / "brc" / "billion_row_om_runner.py"
BRC_1M = ROOT / "scripts" / "brc" / "brc_one_minute_runner.py"

# Python executable used to spawn the benchmark driver
PY = sys.executable or "python3"


def run_command(command_parts):
    """Run a subprocess command and raise on failure.

    Args:
        command_parts: Command and arguments as a list of strings, suitable
            for ``subprocess.run`` without shell expansion.

    This echoes the command for reproducibility and uses ``check=True`` so
    any non-zero exit status aborts the demo early with a clear error.
    """
    print("$", " ".join(command_parts))  # show the exact command
    subprocess.run(command_parts, check=True)  # fail fast if it errors


def run_command_timeout(command_parts, timeout_s: float) -> bool:
    """Run a command with a timeout; return True if finished, False if timed out."""
    print("$", " ".join(command_parts))
    try:
        subprocess.run(command_parts, check=True, timeout=timeout_s)
        return True
    except subprocess.TimeoutExpired:
        print(f"[timeout] {' '.join(command_parts)} after {timeout_s}s")
        return False


def _write_example_csv(path: Path) -> Path:
    """Create a moderately sized CSV with random demo data if missing.

    The file has columns ``a``, ``b``, and ``cat`` to align with demo scripts.

    Returns:
        Path to the created (or pre-existing) CSV file.
    """
    if path.exists():  # avoid regenerating on subsequent runs
        return path
    import csv, random  # local import keeps module scope tidy
    random.seed(42)  # deterministic data for repeatability
    with path.open("w", newline="") as f:
        w = csv.writer(f)
        w.writerow(["a", "b", "cat"])  # header row
        from random import randint, choice
        for _ in range(200000):  # balance speed and substance
            w.writerow([randint(-1000, 1000), randint(-1000, 1000), choice(["x", "y", "z"])])
    return path


def _write_example_small_csv(path: Path) -> Path:
    """Create a tiny CSV with a few hand-picked rows if missing.

    This dataset is used for quick relational and compatibility checks.

    Returns:
        Path to the created (or pre-existing) CSV file.
    """
    if path.exists():
        return path
    import csv
    with path.open("w", newline="") as f:
        w = csv.writer(f)
        w.writerow(["a", "b", "cat"])  # header row
        for a, b, c in [(1, 2, "x"), (-1, 5, "y"), (3, -2, "z")]:
            w.writerow([a, b, c])
    return path


def ensure_data() -> tuple[Path, Path]:
    """Ensure both example datasets exist and return their paths.

    Returns:
        Tuple of Paths ``(example_csv, example_small_csv)``.
    """
    DATA.mkdir(exist_ok=True)  # create data directory if missing
    p1 = _write_example_csv(DATA / "example.csv")
    p2 = _write_example_small_csv(DATA / "example_small.csv")
    return p1, p2


def init_report(path: Path) -> None:
    """Initialize the aggregate report with a title and timestamp.

    Args:
        path: Full path to the aggregate Markdown report to create.
    """
    ts = datetime.now().strftime("%Y-%m-%d %H:%M:%S")  # human-readable timestamp
    with path.open("w") as f:
        f.write(f"# unipandas API demos\n\nGenerated at: {ts}\n\n")
        f.write(f"- Python: `{platform.python_version()}` on `{platform.platform()}`\n")
        f.write(f"- CPU cores: {os.cpu_count()}\n\n")


def append_lines(report_path: Path, lines: list[str]) -> None:
    """Append raw lines to the aggregate report."""
    with report_path.open("a") as f:
        f.write("\n".join(lines) + "\n")


def _ensure_smoke_csv() -> Path:
    """Create a small CSV used by demo scripts if missing."""
    data = ROOT / "data"
    data.mkdir(exist_ok=True)
    sample = data / "smoke.csv"
    if not sample.exists():
        import csv
        with sample.open("w", newline="") as f:
            w = csv.writer(f)
            w.writerow(["a", "b", "cat"])  # columns used by the bench
            w.writerow([1, 2, "x"])
            w.writerow([-1, 5, "y"])
            w.writerow([3, -2, "x"])
    return sample


def append_section(report_path: Path, title: str, md_part: Path) -> None:
    """Append a titled section with content from a Markdown fragment file.

    Args:
        report_path: Aggregate Markdown file to append to.
        title: Section title to add before the included content.
        md_part: Path to a file containing a Markdown fragment to embed.
    """
    with report_path.open("a") as f:
        f.write(f"\n## {title}\n\n")  # Write a second-level heading
        f.write(md_part.read_text())  # Insert the fragment verbatim


def run_demo_and_append() -> None:
    """Run selected scripts under a 3-minute wall-clock budget, updating the report incrementally."""
    sample = _ensure_smoke_csv()
    start = time.perf_counter()
    deadline = start + 180.0
    skipped: list[str] = []
    # 1) Bench backends (API demo) → reports/api_demo/api_demo_smoke.md
    if time.perf_counter() < deadline:
        run_command([
            PY, str(BENCH), str(sample), "--assign", "--query", "a > 0", "--groupby", "cat",
            "--md-out", str(REPORTS / "api_demo_smoke.md"),
        ])
        append_section(REPORT, "API demo smoke run", REPORTS / "api_demo_smoke.md")
        append_lines(REPORT, [f"- Completed bench_backends at {time.strftime('%H:%M:%S')}\n"])  # quick status
    else:
        skipped.append("bench_backends")

    # 2) Compatibility matrix → reports/api_demo/compatibility.md
    if time.perf_counter() < deadline:
        run_command([PY, str(COMPAT), "--md-out", str(REPORTS / "compatibility.md")])
        append_section(REPORT, "Compatibility matrix", REPORTS / "compatibility.md")
        append_lines(REPORT, [f"- Completed compat_matrix at {time.strftime('%H:%M:%S')}\n"])  # quick status
    else:
        skipped.append("compat_matrix")

    # 3) Relational API demos → reports/api_demo/relational_api_demo.md
    if time.perf_counter() < deadline:
        run_command([PY, str(REL), "--md-out", str(REPORTS / "relational_api_demo.md")])
        append_section(REPORT, "Relational API demos", REPORTS / "relational_api_demo.md")
        append_lines(REPORT, [f"- Completed relational_bench at {time.strftime('%H:%M:%S')}\n"])  # quick status
    else:
        skipped.append("relational_bench")

    # 4) BRC small scaffold (write to smoke-specific file) with 30s budget total
    # Use small generated CSV to avoid long runs; still demonstrate end-to-end.
    if time.perf_counter() < deadline:
        ok = run_command_timeout([
            PY, str(BRC), "--rows-per-chunk", "1000", "--num-chunks", "1", "--operation", "groupby",
            "--md-out", str(ROOT / "reports" / "brc" / "billion_row_challenge_smoke.md"),
        ], timeout_s=min(30.0, max(1.0, deadline - time.perf_counter())))
        if not ok:
            skipped.append("billion_row_challenge (timeout)")
    else:
        skipped.append("billion_row_challenge")

    # 5) BRC one-minute runner with 30s budget
    if time.perf_counter() < deadline:
        ok = run_command_timeout([PY, str(BRC_1M), "--budget", "30", "--operation", "groupby"],
                                 timeout_s=min(30.0, max(1.0, deadline - time.perf_counter())))
        if not ok:
            skipped.append("brc_one_minute_runner (timeout)")
    else:
        skipped.append("brc_one_minute_runner")

    # 6) BRC OM runner with 30s per step
    if time.perf_counter() < deadline:
        ok = run_command_timeout([PY, str(BRC_OM), "--budgets", "30"],
                                 timeout_s=min(30.0, max(1.0, deadline - time.perf_counter())))
        if not ok:
            skipped.append("billion_row_om_runner (timeout)")
    else:
        skipped.append("billion_row_om_runner")

    # Note any tasks we did not run due to time budget
    if skipped:
        append_lines(REPORT, ["", "## Skipped due to 3-minute budget", *[f"- {name}" for name in skipped], ""]) 


def main() -> int:
    """Run the 3-minute API demo smoke flow and print the output path.

    Returns:
        0 on success; non-zero on failure (by exception earlier).
    """
    ensure_data()  # ensure inputs for quick demos
    init_report(REPORT)  # start fresh aggregate report
    run_demo_and_append()  # execute selected scripts and aggregate outputs
    print("\nAggregated report:", REPORT)
    return 0


if __name__ == "__main__":
    sys.exit(main())
